{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# 1D Convolution on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WJpFlXLd1_K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd42a761-4f79-470d-9c83-f7676b1ddee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Requirement already satisfied: tlcpack-nightly-cu102 in /usr/local/lib/python3.11/dist-packages (0.15.dev118+g51bdaec6e)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.14.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.12.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels\n",
        "!pip install \"numpy<2.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVzL-yHx1ddS"
      },
      "source": [
        "## 3. Implement `make_conv1d_gpu_scheduler_func` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
        "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then\n",
        "$$\n",
        "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
        "$$\n",
        "\n",
        "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
        "\n",
        "The `make_conv1d_gpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array.\n",
        "You should return both the TVM scheduler and the TVM opterator for\n",
        "1. Input $x$\n",
        "2. Input $y$\n",
        "3. Output $out$\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$.\n",
        "Please see the following cells for usage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tvm\n",
        "import numpy as np\n",
        "from tvm import te\n",
        "\n",
        "# benchmark for tvm implementation\n",
        "def benchmark_conv1d_tvm(schedule_func, M, N, device, a_np, w_np, num_runs=30, repeat=20):\n",
        "    s, A, W, B = schedule_func(M, N)\n",
        "    func = tvm.build(s, [A, W, B], target=\"cuda\")\n",
        "\n",
        "    a_tvm = tvm.nd.array(a_np, device)\n",
        "    w_tvm = tvm.nd.array(w_np, device)\n",
        "    out_tvm = tvm.nd.array(np.zeros((M + N - 1,), dtype=a_np.dtype), device)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, device, number=num_runs, repeat=repeat)\n",
        "    cost = evaluator(a_tvm, w_tvm, out_tvm).mean  # average time in seconds\n",
        "    return cost, out_tvm.asnumpy(), func, (s, A, W, B)\n",
        "\n",
        "# benchmark for numpy\n",
        "def benchmark_conv1d_numpy(a_np, w_np, num_runs=10):\n",
        "    t0 = time.time()\n",
        "    out = None\n",
        "    for _ in range(num_runs):\n",
        "        out = np.convolve(a_np, w_np)\n",
        "    t1 = time.time()\n",
        "    return (t1 - t0) / num_runs, out\n"
      ],
      "metadata": {
        "id": "wOzY-faZ9LRX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np baseline\n",
        "M = 16384\n",
        "N = 32\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(M).astype(dtype)\n",
        "w_np = np.random.rand(N).astype(dtype)\n",
        "ref = np.convolve(a_np, w_np)\n",
        "\n",
        "\n",
        "# naive baseline\n",
        "def make_conv1d_gpu_scheduler_naive(M, N, dtype=\"float32\", verbose=True):\n",
        "    A = te.placeholder((M,), name=\"A\", dtype=dtype)\n",
        "    W = te.placeholder((N,), name=\"W\", dtype=dtype)\n",
        "    k = te.reduce_axis((0, M + N - 1), \"k\")   # k in [0, M+N-1)\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),   # output shape, n from (0, M + N - 1)\n",
        "        # if_then_else: if satisfy \"any\" condition, return 0 else A[k] * W[n - k]\n",
        "        lambda n: te.sum(tvm.tir.if_then_else(\n",
        "            tvm.tir.any(k < 0, k >= M, n - k < 0, n - k >= N),\n",
        "            tvm.tir.const(0.0, \"float32\"),\n",
        "            A[k] * W[n - k]), axis=k),\n",
        "        name=\"B\",\n",
        "    )\n",
        "    s = te.create_schedule(B.op)\n",
        "    i = B.op.axis[0]\n",
        "    s[B].bind(i, te.thread_axis(\"blockIdx.x\"))\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B"
      ],
      "metadata": {
        "id": "O6r3IYwieDUa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# naive TVM\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_naive, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Naive] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPjjXc7k9zo3",
        "outputId": "486097e1-d909-4dc4-8444-8f41a6729d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 16415)\n",
            "        B[blockIdx_x] = T.float32(0)\n",
            "        for k in range(16415):\n",
            "            B[blockIdx_x] = B[blockIdx_x] + T.if_then_else(16384 <= k or blockIdx_x - k < 0 or 32 <= blockIdx_x - k, T.float32(0), A[k] * W[blockIdx_x - k])\n",
            "====================================================================================================\n",
            "[TVM Naive] time: 18.2860 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize v1, compute refactor\n",
        "def make_conv1d_gpu_scheduler_v1(M, N, dtype=\"float32\", verbose=True):\n",
        "    A = te.placeholder((M,), name=\"A\", dtype=dtype)\n",
        "    W = te.placeholder((N,), name=\"W\", dtype=dtype)\n",
        "    r = te.reduce_axis((0, N), name=\"r\")\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),\n",
        "        lambda i: te.sum(\n",
        "            tvm.tir.if_then_else(\n",
        "                tvm.tir.all(i - r >= 0, i - r < M),\n",
        "                A[i - r],\n",
        "                tvm.tir.const(0, dtype)\n",
        "            ) * W[r],\n",
        "            axis=r\n",
        "        ),\n",
        "        name=\"B\"\n",
        "    )\n",
        "\n",
        "    s = te.create_schedule(B.op)\n",
        "    i = B.op.axis[0]\n",
        "    s[B].bind(i, te.thread_axis(\"blockIdx.x\"))\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B\n",
        "\n",
        "# optimize v1: less if-else\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_v1, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Opt v1] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEZ2y-z_-_pf",
        "outputId": "b23b37a3-4212-4991-9392-dd8804e91a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 16415)\n",
            "        B[blockIdx_x] = T.float32(0)\n",
            "        for r in range(32):\n",
            "            B[blockIdx_x] = B[blockIdx_x] + T.if_then_else(0 <= blockIdx_x - r and blockIdx_x - r < 16384, A[blockIdx_x - r], T.float32(0)) * W[r]\n",
            "====================================================================================================\n",
            "[TVM Opt v1] time: 0.1070 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize v2: v1 + basic threads\n",
        "def make_conv1d_gpu_scheduler_v2(M, N, dtype=\"float32\", verbose=True):\n",
        "    s, A, W, B = make_conv1d_gpu_scheduler_v1(M, N, dtype, False)\n",
        "\n",
        "    # out axis\n",
        "    i = B.op.axis[0]\n",
        "    block_i, thread_i = s[B].split(i, factor=8)\n",
        "\n",
        "    # bind to block and thread\n",
        "    s[B].bind(block_i, te.thread_axis(\"blockIdx.x\"))\n",
        "    s[B].bind(thread_i, te.thread_axis(\"threadIdx.x\"))\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B\n",
        "\n",
        "\n",
        "# optimize v2\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_v2, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Opt v2] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmN1ByeXetEj",
        "outputId": "28b5feaa-2f5a-4f2e-a8d1-e9496f481202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 2052)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 8)\n",
            "        if T.likely(blockIdx_x * 8 + threadIdx_x < 16415):\n",
            "            B[blockIdx_x * 8 + threadIdx_x] = T.float32(0)\n",
            "        for r in range(32):\n",
            "            if T.likely(blockIdx_x * 8 + threadIdx_x < 16415):\n",
            "                B[blockIdx_x * 8 + threadIdx_x] = B[blockIdx_x * 8 + threadIdx_x] + T.if_then_else(0 <= blockIdx_x * 8 + threadIdx_x - r and blockIdx_x * 8 + threadIdx_x - r < 16384, A[blockIdx_x * 8 + threadIdx_x - r], T.float32(0)) * W[r]\n",
            "====================================================================================================\n",
            "[TVM Opt v2] time: 0.0251 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize v3: v1 + 2D threads\n",
        "def make_conv1d_gpu_scheduler_v3(M, N, dtype=\"float32\", verbose=True):\n",
        "    s, A, W, B = make_conv1d_gpu_scheduler_v1(M, N, dtype, False)\n",
        "\n",
        "    i = B.op.axis[0]\n",
        "    block_i, thread_i = s[B].split(i, factor=16)\n",
        "    warp_i, lane_i = s[B].split(thread_i, factor=4)\n",
        "\n",
        "    s[B].bind(block_i, te.thread_axis(\"blockIdx.x\"))\n",
        "    s[B].bind(warp_i, te.thread_axis(\"threadIdx.y\"))\n",
        "    s[B].bind(lane_i, te.thread_axis(\"threadIdx.x\"))\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B\n",
        "\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_v3, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Opt v3] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1--rg1KLs2dW",
        "outputId": "2771b627-0ab1-44c3-c2e0-89e7bef2a87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 1026)\n",
            "        threadIdx_y = T.launch_thread(\"threadIdx.y\", 4)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 4)\n",
            "        if T.likely(blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "            B[blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x] = T.float32(0)\n",
            "        for r in range(32):\n",
            "            if T.likely(blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B[blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x] = B[blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x] + T.if_then_else(0 <= blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x - r and blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x - r < 16384, A[blockIdx_x * 16 + threadIdx_y * 4 + threadIdx_x - r], T.float32(0)) * W[r]\n",
            "====================================================================================================\n",
            "[TVM Opt v3] time: 0.0158 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize v4: v1 + 1D thread + cache + split reduce\n",
        "def make_conv1d_gpu_scheduler_v4(M, N, dtype=\"float32\", verbose=True):\n",
        "    s, A, W, B = make_conv1d_gpu_scheduler_v1(M, N, dtype, False)\n",
        "\n",
        "    # IMPORTANT: create caches BEFORE thread binding\n",
        "    C_local = s.cache_write(B, \"local\")\n",
        "    W_shared = s.cache_read(W, \"shared\", [C_local])\n",
        "\n",
        "    i = B.op.axis[0]\n",
        "    block_i, thread_i = s[B].split(i, factor=32)\n",
        "    s[B].bind(block_i, te.thread_axis(\"blockIdx.x\"))\n",
        "    s[B].bind(thread_i, te.thread_axis(\"threadIdx.x\"))\n",
        "\n",
        "    # schedule the local cache\n",
        "    s[C_local].compute_at(s[B], thread_i)\n",
        "\n",
        "    i_local = C_local.op.axis[0]\n",
        "    rx = C_local.op.reduce_axis[0]\n",
        "    # split the reduction axis\n",
        "    rxo, rxi = s[C_local].split(rx, factor=4)\n",
        "\n",
        "    # schedule shared memory\n",
        "    s[W_shared].compute_at(s[C_local], rxo)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B\n",
        "\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_v4, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Opt v4] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzizcGos7cV",
        "outputId": "27f7b10f-163b-496a-c894-3639a9c6ce5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 513)\n",
            "        B_local = T.allocate([1], \"float32\", \"local\")\n",
            "        W_shared = T.allocate([4], \"float32\", \"shared\")\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 32)\n",
            "        B_local_1 = T.Buffer((1,), data=B_local, scope=\"local\", align=4)\n",
            "        B_local_1[0] = T.float32(0)\n",
            "        for r_outer in range(8):\n",
            "            W_shared_1 = T.Buffer((4,), data=W_shared, scope=\"shared\", align=16)\n",
            "            for ax0 in range(4):\n",
            "                W_shared_1[ax0] = W[r_outer * 4 + ax0]\n",
            "            for r_inner in range(4):\n",
            "                if T.likely(blockIdx_x * 32 + threadIdx_x < 16415):\n",
            "                    B_local_1[0] = B_local_1[0] + T.if_then_else(0 <= blockIdx_x * 32 + threadIdx_x - r_inner - r_outer * 4 and blockIdx_x * 32 + threadIdx_x - r_inner - r_outer * 4 < 16384, A[blockIdx_x * 32 + threadIdx_x - r_inner - r_outer * 4], T.float32(0)) * W_shared_1[r_inner]\n",
            "        if T.likely(blockIdx_x * 32 + threadIdx_x < 16415):\n",
            "            B[blockIdx_x * 32 + threadIdx_x] = B_local_1[0]\n",
            "====================================================================================================\n",
            "[TVM Opt v4] time: 0.0147 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKlCSCAEeMAy",
        "outputId": "5196b2f2-5abc-4cfc-8cf8-e1b25b5c0e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 23 19:26:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0             26W /   70W |     102MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize v5: v4 + 2D threads + unroll\n",
        "def make_conv1d_gpu_scheduler_v5(M, N, dtype=\"float32\", verbose=True):\n",
        "    s, A, W, B = make_conv1d_gpu_scheduler_v1(M, N, dtype, False)\n",
        "\n",
        "    C_local = s.cache_write(B, \"local\")\n",
        "    W_shared = s.cache_read(W, \"shared\", [C_local])\n",
        "\n",
        "    i = B.op.axis[0]\n",
        "    block_i, thread_i = s[B].split(i, factor=32)\n",
        "    # split 2D threads\n",
        "    warp_i, lane_i = s[B].split(thread_i, factor=4)\n",
        "    s[B].bind(block_i, te.thread_axis(\"blockIdx.x\"))\n",
        "    s[B].bind(warp_i, te.thread_axis(\"threadIdx.y\"))\n",
        "    s[B].bind(lane_i, te.thread_axis(\"threadIdx.x\"))\n",
        "\n",
        "    s[C_local].compute_at(s[B], lane_i)\n",
        "\n",
        "    rx = C_local.op.reduce_axis[0]\n",
        "\n",
        "    # split the reduce axis\n",
        "    rxo, rxi = s[C_local].split(rx, factor=8)\n",
        "\n",
        "    s[W_shared].compute_at(s[C_local], rxo)\n",
        "\n",
        "    # unroll\n",
        "    s[C_local].unroll(rxi)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B\n",
        "\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_v5, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Opt v5] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVgsJFdJz9gX",
        "outputId": "ee70c672-5ec1-40cf-f338-1c7f2791db50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 513)\n",
            "        B_local = T.allocate([1], \"float32\", \"local\")\n",
            "        W_shared = T.allocate([8], \"float32\", \"shared\")\n",
            "        threadIdx_y = T.launch_thread(\"threadIdx.y\", 8)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 4)\n",
            "        B_local_1 = T.Buffer((1,), data=B_local, scope=\"local\", align=4)\n",
            "        B_local_1[0] = T.float32(0)\n",
            "        for r_outer in range(4):\n",
            "            W_shared_1 = T.Buffer((8,), data=W_shared, scope=\"shared\", align=32)\n",
            "            for ax0 in range(8):\n",
            "                W_shared_1[ax0] = W[r_outer * 8 + ax0]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(0 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 8 + threadIdx_y - r_outer * 2 < 4096, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8], T.float32(0)) * W_shared_1[0]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(1 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 < 16385, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 1], T.float32(0)) * W_shared_1[1]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(2 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 < 16386, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 2], T.float32(0)) * W_shared_1[2]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(3 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 < 16387, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 3], T.float32(0)) * W_shared_1[3]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(1 <= blockIdx_x * 8 + threadIdx_y - r_outer * 2 and blockIdx_x * 8 + threadIdx_y - r_outer * 2 < 4097, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 4], T.float32(0)) * W_shared_1[4]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(5 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 < 16389, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 5], T.float32(0)) * W_shared_1[5]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(6 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 < 16390, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 6], T.float32(0)) * W_shared_1[6]\n",
            "            if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "                B_local_1[0] = B_local_1[0] + T.if_then_else(7 <= blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 and blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 < 16391, A[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x - r_outer * 8 - 7], T.float32(0)) * W_shared_1[7]\n",
            "        if T.likely(blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x < 16415):\n",
            "            B[blockIdx_x * 32 + threadIdx_y * 4 + threadIdx_x] = B_local_1[0]\n",
            "====================================================================================================\n",
            "[TVM Opt v5] time: 0.0124 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tvm\n",
        "from tvm import te\n",
        "import numpy as np\n",
        "from tvm import autotvm\n",
        "from tvm.autotvm.tuner import XGBTuner, RandomTuner\n",
        "import time\n",
        "\n",
        "@autotvm.template(\"conv1d_gpu\")\n",
        "def conv1d_gpu_template_simple(M, N, dtype=\"float32\"):\n",
        "    A = te.placeholder((M,), name=\"A\", dtype=dtype)\n",
        "    W = te.placeholder((N,), name=\"W\", dtype=dtype)\n",
        "    r = te.reduce_axis((0, N), name=\"r\")\n",
        "\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),\n",
        "        lambda i: te.sum(\n",
        "            tvm.tir.if_then_else(\n",
        "                tvm.tir.all(i - r >= 0, i - r < M),\n",
        "                A[i - r],\n",
        "                tvm.tir.const(0, dtype)\n",
        "            ) * W[r],\n",
        "            axis=r\n",
        "        ),\n",
        "        name=\"B\"\n",
        "    )\n",
        "\n",
        "    s = te.create_schedule(B.op)\n",
        "    cfg = autotvm.get_config()\n",
        "\n",
        "    cfg.define_knob(\"use_cache\", [0, 1])\n",
        "    cfg.define_knob(\"thread_x\", [1,2,4,8,16])\n",
        "    i = B.op.axis[0]\n",
        "\n",
        "    if cfg[\"use_cache\"].val:\n",
        "        C_local = s.cache_write(B, \"local\")\n",
        "        W_shared = s.cache_read(W, \"shared\", [C_local])\n",
        "\n",
        "    block_i, thread_i = s[B].split(i, factor=cfg[\"thread_x\"].val)\n",
        "    s[B].bind(block_i, te.thread_axis(\"blockIdx.x\"))\n",
        "    s[B].bind(thread_i, te.thread_axis(\"threadIdx.x\"))\n",
        "\n",
        "    if cfg[\"use_cache\"].val:\n",
        "        C_local = s.cache_write(B, \"local\")\n",
        "        W_shared = s.cache_read(W, \"shared\", [C_local])\n",
        "\n",
        "        s[C_local].compute_at(s[B], thread_i)\n",
        "        rx = C_local.op.reduce_axis[0]\n",
        "\n",
        "        cfg.define_knob(\"split_reduction\", [0, 1])\n",
        "        if cfg[\"split_reduction\"].val:\n",
        "            rxo, rxi = s[C_local].split(rx, factor=8)\n",
        "            s[W_shared].compute_at(s[C_local], rxo)\n",
        "        else:\n",
        "            s[W_shared].compute_at(s[C_local], rx)\n",
        "\n",
        "    return s, [A, W, B]\n",
        "\n",
        "def tune_conv1d_gpu_simple(M, N, dtype=\"float32\",\n",
        "                          log_file=\"conv1d_gpu_simple.log\",\n",
        "                          tuning_rounds=100):\n",
        "    task = autotvm.task.create(\"conv1d_gpu_simple\", args=(M, N, dtype), target=\"cuda\")\n",
        "    measure_option = autotvm.measure_option(\n",
        "        builder=autotvm.LocalBuilder(),\n",
        "        runner=autotvm.LocalRunner(number=5, repeat=3, min_repeat_ms=100, timeout=4)\n",
        "    )\n",
        "\n",
        "    tuner = RandomTuner(task)\n",
        "\n",
        "    tuner.tune(\n",
        "        n_trial=tuning_rounds,\n",
        "        measure_option=measure_option,\n",
        "        callbacks=[autotvm.callback.log_to_file(log_file)]\n",
        "    )\n",
        "\n",
        "    with autotvm.apply_history_best(log_file):\n",
        "        with tvm.target.Target(\"cuda\"):\n",
        "            s, args = conv1d_gpu_template_simple(M, N, dtype)\n",
        "            func = tvm.build(s, args)\n",
        "\n",
        "    a_np = np.random.rand(M).astype(dtype)\n",
        "    w_np = np.random.rand(N).astype(dtype)\n",
        "\n",
        "    dev = tvm.cuda()\n",
        "    a_tvm = tvm.nd.array(a_np, dev)\n",
        "    w_tvm = tvm.nd.array(w_np, dev)\n",
        "    b_tvm = tvm.nd.array(np.zeros((M + N - 1,), dtype=dtype), dev)\n",
        "\n",
        "    func(a_tvm, w_tvm, b_tvm)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, dev, number=10, repeat=3)\n",
        "    time_cost = evaluator(a_tvm, w_tvm, b_tvm).mean\n",
        "\n",
        "    ref = np.convolve(a_np, w_np)\n",
        "\n",
        "    np.testing.assert_allclose(b_tvm.asnumpy(), ref, rtol=1e-4)\n",
        "\n",
        "    print(f\"best config time usage: {time_cost * 1e3:.4f} ms\")\n",
        "    return func, (time_cost * 1e3)\n",
        "\n",
        "def make_conv1d_gpu_scheduler_autotvm_simple(M, N, dtype=\"float32\", verbose=True, log_file=\"conv1d_gpu_simple.log\"):\n",
        "    with autotvm.apply_history_best(log_file):\n",
        "        with tvm.target.Target(\"cuda\"):\n",
        "            s, args = conv1d_gpu_template_simple(M, N, dtype)\n",
        "            if verbose:\n",
        "                print(\"=\" * 100)\n",
        "                print(tvm.lower(s, args, simple_mode=True))\n",
        "                print(\"=\" * 100)\n",
        "            return s, args[0], args[1], args[2]\n",
        "\n",
        "def benchmark_conv1d_tvm(schedule_func, M, N, device, a_np, w_np, num_runs=10, repeat=3, log_file=None):\n",
        "    if log_file and 'autotvm' in schedule_func.__name__:\n",
        "        s, A, W, B = schedule_func(M, N, log_file=log_file)\n",
        "    else:\n",
        "        s, A, W, B = schedule_func(M, N)\n",
        "\n",
        "    func = tvm.build(s, [A, W, B], target=\"cuda\")\n",
        "    a_tvm = tvm.nd.array(a_np, device)\n",
        "    w_tvm = tvm.nd.array(w_np, device)\n",
        "    out_tvm = tvm.nd.array(np.zeros((M + N - 1,), dtype=a_np.dtype), device)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, device, number=num_runs, repeat=repeat)\n",
        "    cost = evaluator(a_tvm, w_tvm, out_tvm).mean\n",
        "\n",
        "    return cost, out_tvm.asnumpy(), func, (s, A, W, B)\n",
        "\n"
      ],
      "metadata": {
        "id": "C7fPO_9Usve_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = 16384\n",
        "N = 32\n",
        "dtype = 'float32'\n",
        "log_file = \"conv1d_gpu_simple.log\"\n",
        "\n",
        "tuning_rounds = 50\n",
        "\n",
        "print(\"===== autotvm =====\")\n",
        "tune_conv1d_gpu_simple(M, N, dtype, log_file, tuning_rounds)\n",
        "\n",
        "a_np = np.random.rand(M).astype(dtype)\n",
        "w_np = np.random.rand(N).astype(dtype)\n",
        "ref = np.convolve(a_np, w_np)\n",
        "\n",
        "dev = tvm.cuda()\n",
        "autotvm_time, autotvm_res, _, _ = benchmark_conv1d_tvm(\n",
        "    make_conv1d_gpu_scheduler_autotvm_simple, M, N, dev, a_np, w_np,\n",
        "    log_file=log_file\n",
        ")\n",
        "np.testing.assert_allclose(autotvm_res, ref, rtol=1e-4)\n",
        "\n",
        "print(f\"[TVM Opt Auto] time: {autotvm_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRqsnfuI_UuQ",
        "outputId": "543e2f7d-e33a-4bd6-8fd9-ef6c381aeaa0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== autotvm =====\n",
            "best config time usage: 0.0404 ms\n",
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((16384,), \"float32\"), W: T.Buffer((32,), \"float32\"), B: T.Buffer((16415,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 16415)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 1)\n",
            "        B[blockIdx_x] = T.float32(0)\n",
            "        for r in range(32):\n",
            "            B[blockIdx_x] = B[blockIdx_x] + T.if_then_else(0 <= blockIdx_x - r and blockIdx_x - r < 16384, A[blockIdx_x - r], T.float32(0)) * W[r]\n",
            "====================================================================================================\n",
            "[TVM Opt Auto] time: 0.0405 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUT5WMw41ddU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1bcce4-2f18-4ca4-9ea3-c7a90f326fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NumPy]   time: 0.2369 ms\n"
          ]
        }
      ],
      "source": [
        "# numPy baseline\n",
        "numpy_time, numpy_out = benchmark_conv1d_numpy(a_np, w_np, num_runs=10)\n",
        "print(f\"[NumPy]   time: {numpy_time*1e3:.4f} ms\")\n",
        "np.testing.assert_allclose(numpy_out, ref, rtol=1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def benchmark_conv1d_torch(a_np, w_np, num_runs=10, device='cuda'):\n",
        "\n",
        "    a_torch = torch.tensor(a_np, device=device, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "    w_torch = torch.tensor(w_np, device=device, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "    w_torch = w_torch.flip(-1)\n",
        "\n",
        "    for _ in range(5):\n",
        "        _ = F.conv1d(a_torch, w_torch, padding=(w_np.shape[0] - 1))\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        out_torch = F.conv1d(a_torch, w_torch, padding=(w_np.shape[0] - 1))\n",
        "    torch.cuda.synchronize()\n",
        "    t1 = time.time()\n",
        "\n",
        "    avg_time = (t1 - t0) / num_runs\n",
        "    out_arr = out_torch.view(-1).cpu().detach().numpy()\n",
        "    return avg_time, out_arr\n",
        "\n",
        "torch_time, torch_res = benchmark_conv1d_torch(a_np, w_np, num_runs=10, device='cuda')\n",
        "np.testing.assert_allclose(torch_res, ref, rtol=1e-4)\n",
        "print(f\"[Torch] time: {torch_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbeIqPqY_Z0P",
        "outputId": "c56bfe44-9bfe-4d1d-869f-83404eb971bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Torch] time: 0.1491 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_6kV5BU1ddU",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ecf6a26-24f8-4424-a035-593422f6d4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipytest\n",
            "  Downloading ipytest-0.14.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipytest) (24.2)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.11/dist-packages (from ipytest) (8.3.5)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=5.4->ipytest) (1.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->ipytest)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.13)\n",
            "Downloading ipytest-0.14.2-py3-none-any.whl (18 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipytest\n",
            "Successfully installed ipytest-0.14.2 jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "# pytest\n",
        "%pip install ipytest\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest\n",
        "import tvm\n",
        "import torch\n",
        "import pytest\n",
        "import timeit\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "dev = tvm.cuda(0)\n",
        "\n",
        "make_conv1d_gpu_scheduler = make_conv1d_gpu_scheduler_v5\n",
        "\n",
        "def ans_np(a_np, w_np):\n",
        "    a_np = a_np.flatten()\n",
        "    w_np = w_np.flatten()\n",
        "    return np.convolve(a_np, w_np)\n",
        "\n",
        "def make_conv1d_gpu_func(M, N):\n",
        "    s, A, W, O = make_conv1d_gpu_scheduler(M, N)\n",
        "    func = tvm.build(s, [A, W, O], \"cuda\")\n",
        "    return func\n",
        "\n",
        "\n",
        "def ans_torch(a_torch, w_torch):\n",
        "    M, N = a_torch.size(0), w_torch.size(0)\n",
        "    torch.cuda.synchronize()\n",
        "    b_torch = F.conv1d(a_torch, w_torch, bias=None, stride=1,\n",
        "                       padding=(N - 1), dilation=1, groups=1)\n",
        "    torch.cuda.synchronize()\n",
        "    return b_torch\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('execution_number', range(5))\n",
        "def test1_M1_N1(execution_number):\n",
        "    # Define dimension\n",
        "    M = 1\n",
        "    N = 1\n",
        "    func = make_conv1d_gpu_func(M, N)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=execution_number)\n",
        "    a_np = np.random.rand(M).astype(np.float32)\n",
        "    w_np = np.random.rand(N).astype(np.float32)\n",
        "    b_np = ans_np(a_np, w_np)\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('execution_number', [1, 10, 100, 1000, 10000])\n",
        "def test1_Mvar_N1024(execution_number):\n",
        "    # Define dimension\n",
        "    M = execution_number\n",
        "    N = 1024\n",
        "    func = make_conv1d_gpu_func(M, N)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=1024)\n",
        "    a_np = np.random.rand(M).astype(np.float32)\n",
        "    w_np = np.random.rand(N).astype(np.float32)\n",
        "    b_np = ans_np(a_np, w_np)\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('execution_number', [1, 10, 100, 1000, 10000])\n",
        "def test1_M1024_Nvar(execution_number):\n",
        "    # Define dimension\n",
        "    M = 1024\n",
        "    N = execution_number\n",
        "    func = make_conv1d_gpu_func(M, N)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=1024)\n",
        "    a_np = np.random.rand(M).astype(np.float32)\n",
        "    w_np = np.random.rand(N).astype(np.float32)\n",
        "    b_np = ans_np(a_np, w_np)\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngrJS-g85pz-",
        "outputId": "4057a6cf-368e-4031-9453-fc5eb647d770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                              [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 9.11s\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}