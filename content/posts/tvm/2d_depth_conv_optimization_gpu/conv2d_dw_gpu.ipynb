{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# Depthwise-seperable 2D Convolution on GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD2GHA5WVSow"
      },
      "source": [
        "## 1. Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Phf10Wb1VxoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa37d310-85aa-4993-b110-d56893929e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Requirement already satisfied: tlcpack-nightly-cu102 in /usr/local/lib/python3.11/dist-packages (0.15.dev118+g51bdaec6e)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.14.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.13.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels\n",
        "!pip install \"numpy<2.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1dTOTtqVSoy"
      },
      "source": [
        "## 3. Implement `make_dwsp_conv2d_gpu_scheduler` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 2D convolution and use TVM to optimize it.\n",
        "Please use zero padding and unit stride.\n",
        "You can assume kernel size to be an odd number.\n",
        "The padding will equals to kernel size minus ones.\n",
        "In this case, the output image will preserve the input image dimension.\n",
        "\n",
        "The `make_dwsp_conv2d_gpu_scheduler` takes following arguments:\n",
        "1. Batch size $B$;\n",
        "2. Input channel size $C$;\n",
        "3. Input image height $H$;\n",
        "4. Input image width $W$;\n",
        "5. Output number of channels $O$;\n",
        "6. Kernel size $K$\n",
        "\n",
        "You should return both the TVM scheduler and the TVM opterator for\n",
        "1. Input tensor $x$ with size (B, C, H, W)\n",
        "2. Input kernel weight $y$ with size (O, 1, K, K)\n",
        "3. Output $out$ with size (B, O, H, W)\n",
        "\n",
        "The scheduler should be able to used to build a function with signature $func(x, y, out)$.\n",
        "Please see the following cells the usage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tvm\n",
        "import numpy as np\n",
        "from tvm import te\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "# benchmark for tvm implementation\n",
        "def benchmark_conv2d_tvm(schedule_func, B, C, H, W, K, device, a_np, w_np, num_runs=5, repeat=5):\n",
        "    s, inp, ker, out = schedule_func(B, C, H, W, K)\n",
        "    func = tvm.build(s, [inp, ker, out], \"cuda\")\n",
        "\n",
        "    dev = tvm.cuda(0)\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((B, C, H, W), dtype), dev)\n",
        "    evaluator = func.time_evaluator(func.entry_name, dev, number=num_runs, repeat=repeat)\n",
        "    cost = evaluator(a, w, b).mean\n",
        "    return cost, b.asnumpy(), func\n",
        "\n",
        "\n",
        "# pytorch ref and time usage\n",
        "def pytorch_depthwise_conv2d(input_data, kernel, device='cuda', number=10, repeat=3, warmup=2):\n",
        "    input_tensor = torch.from_numpy(input_data).to(device)\n",
        "    kernel_tensor = torch.from_numpy(kernel).to(device)\n",
        "    _, _, K_h, K_w = kernel.shape\n",
        "    pad_h = (K_h - 1) // 2\n",
        "    pad_w = (K_w - 1) // 2\n",
        "\n",
        "    C = input_data.shape[1]\n",
        "\n",
        "    def compute():\n",
        "        with torch.no_grad():\n",
        "            return F.conv2d(input_tensor, kernel_tensor,\n",
        "                           padding=(pad_h, pad_w),\n",
        "                           groups=C)\n",
        "    for _ in range(warmup):\n",
        "        output = compute()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    times = []\n",
        "    for _ in range(repeat):\n",
        "        torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "\n",
        "        for _ in range(number):\n",
        "            output = compute()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        end_time = time.time()\n",
        "        times.append((end_time - start_time) / number * 1000)\n",
        "\n",
        "    avg_time = sum(times) / len(times)\n",
        "    return output.cpu().numpy(), avg_time\n",
        "\n",
        "B, C, H, W, K = 3, 4, 16, 32, 7\n",
        "# B, C, H, W, K = 1, 5, 128, 128, 3\n",
        "dtype = 'float32'\n",
        "a_np = np.random.rand(B, C, H, W).astype(dtype)\n",
        "w_np = np.random.rand(C, 1, K, K).astype(dtype)\n",
        "\n",
        "ref, pytorch_time = pytorch_depthwise_conv2d(a_np, w_np)\n",
        "print(f\"2DConv PyTorch: {pytorch_time:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNEwpWbWO6An",
        "outputId": "bcc527cb-0c09-4e70-8847-bb470927fba6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2DConv PyTorch: 0.0696 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def base_declaration(B, C, H, W, K):\n",
        "    assert K % 2 == 1\n",
        "    inp = te.placeholder((B, C, H, W), name=\"A\")\n",
        "    ker = te.placeholder((C, 1, K, K), name=\"W\")\n",
        "\n",
        "    ry = te.reduce_axis((0, K), name='ry')\n",
        "    rx = te.reduce_axis((0, K), name='rx')\n",
        "    pad_h = (K - 1) // 2\n",
        "    pad_w = (K - 1) // 2\n",
        "\n",
        "    padded = te.compute(\n",
        "        (B, C, H + 2*pad_h, W + 2*pad_w),\n",
        "        lambda b, c, h, w: tvm.tir.if_then_else(\n",
        "            tvm.tir.all(h >= pad_h, h < H + pad_h, w >= pad_w, w < W + pad_w),\n",
        "            inp[b, c, h - pad_h, w - pad_w],\n",
        "            tvm.tir.const(0.0, \"float32\")\n",
        "        ),\n",
        "        name=\"padded\"\n",
        "    )\n",
        "\n",
        "    out = te.compute(\n",
        "        (B, C, H, W),\n",
        "        lambda b, c, h, w: te.sum(\n",
        "            padded[b, c, h + ry, w + rx] * ker[c, 0, ry, rx],\n",
        "            axis=[ry, rx]\n",
        "        ),\n",
        "        name=\"depthwise_conv\"\n",
        "    )\n",
        "\n",
        "    s = te.create_schedule(out.op)\n",
        "    return s, inp, ker, out, padded\n",
        "\n",
        "def make_dwsp_conv2d_gpu_scheduler_naive(B, C, H, W, K, verbose=True):\n",
        "    s, inp, ker, out, padded = base_declaration(B, C, H, W, K)\n",
        "    block_x = te.thread_axis(\"blockIdx.x\")\n",
        "    b, c, h, w = s[out].op.axis\n",
        "    s[out].bind(b, block_x)\n",
        "    # compute inline: only compute padding when calculating the out\n",
        "    s[padded].compute_inline()\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [inp, ker, out], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, inp, ker, out\n",
        "\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func = benchmark_conv2d_tvm(\n",
        "    make_dwsp_conv2d_gpu_scheduler_naive, B, C, H, W, K, dev, a_np, w_np, num_runs=5, repeat=5\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Naive] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AizT2IWhUPve",
        "outputId": "2f520057-b96c-4dc2-9fe0-9c5426d418a3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), depthwise_conv: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 3)\n",
            "        for c, h, w in T.grid(4, 16, 32):\n",
            "            depthwise_conv_1 = T.Buffer((6144,), data=depthwise_conv.data)\n",
            "            depthwise_conv_1[blockIdx_x * 2048 + c * 512 + h * 32 + w] = T.float32(0)\n",
            "            for ry, rx in T.grid(7, 7):\n",
            "                cse_var_2: T.int32 = h + ry\n",
            "                cse_var_1: T.int32 = w + rx\n",
            "                A_1 = T.Buffer((6144,), data=A.data)\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                depthwise_conv_1[blockIdx_x * 2048 + c * 512 + h * 32 + w] = depthwise_conv_1[blockIdx_x * 2048 + c * 512 + h * 32 + w] + T.if_then_else(3 <= cse_var_2 and cse_var_2 < 19 and 3 <= cse_var_1 and cse_var_1 < 35, A_1[blockIdx_x * 2048 + c * 512 + h * 32 + ry * 32 + w + rx - 99], T.float32(0)) * W_1[c * 49 + ry * 7 + rx]\n",
            "====================================================================================================\n",
            "[TVM Naive] time: 3.2904 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt v1: 2d block architecture\n",
        "def make_dwsp_conv2d_gpu_scheduler_v1(B, C, H, W, K, verbose=True):\n",
        "    s, inp, ker, out, padded = base_declaration(B, C, H, W, K)\n",
        "    block_x = te.thread_axis(\"blockIdx.x\")\n",
        "    block_y = te.thread_axis(\"blockIdx.y\")\n",
        "\n",
        "    b, c, h, w = s[out].op.axis\n",
        "    s[out].bind(b, block_x)\n",
        "    s[out].bind(c, block_y)\n",
        "    s[padded].compute_inline()\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [inp, ker, out], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, inp, ker, out\n",
        "\n",
        "dev = tvm.cuda()\n",
        "t, res, func = benchmark_conv2d_tvm(\n",
        "    make_dwsp_conv2d_gpu_scheduler_v1, B, C, H, W, K, dev, a_np, w_np, num_runs=5, repeat=5\n",
        ")\n",
        "np.testing.assert_allclose(res, ref, rtol=1e-4)\n",
        "print(f\"[TVM v1] time: {t*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPTD6vCfZfcG",
        "outputId": "202d1125-b80d-499a-f2c2-b1b3d775b61e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), depthwise_conv: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 3)\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 4)\n",
            "        for h, w in T.grid(16, 32):\n",
            "            depthwise_conv_1 = T.Buffer((6144,), data=depthwise_conv.data)\n",
            "            depthwise_conv_1[blockIdx_x * 2048 + blockIdx_y * 512 + h * 32 + w] = T.float32(0)\n",
            "            for ry, rx in T.grid(7, 7):\n",
            "                cse_var_2: T.int32 = h + ry\n",
            "                cse_var_1: T.int32 = w + rx\n",
            "                A_1 = T.Buffer((6144,), data=A.data)\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                depthwise_conv_1[blockIdx_x * 2048 + blockIdx_y * 512 + h * 32 + w] = depthwise_conv_1[blockIdx_x * 2048 + blockIdx_y * 512 + h * 32 + w] + T.if_then_else(3 <= cse_var_2 and cse_var_2 < 19 and 3 <= cse_var_1 and cse_var_1 < 35, A_1[blockIdx_x * 2048 + blockIdx_y * 512 + h * 32 + ry * 32 + w + rx - 99], T.float32(0)) * W_1[blockIdx_y * 49 + ry * 7 + rx]\n",
            "====================================================================================================\n",
            "[TVM v1] time: 0.7687 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt v2: block fuse\n",
        "def make_dwsp_conv2d_gpu_scheduler_v2(B, C, H, W, K, verbose=True):\n",
        "    s, inp, ker, out, padded = base_declaration(B, C, H, W, K)\n",
        "    block_x = te.thread_axis(\"blockIdx.x\")\n",
        "    block_y = te.thread_axis(\"blockIdx.y\")\n",
        "\n",
        "    b, c, h, w = s[out].op.axis\n",
        "    bc = s[out].fuse(b, c)\n",
        "    s[out].bind(bc, block_x)\n",
        "    s[out].bind(h, block_y)\n",
        "    s[padded].compute_inline()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [inp, ker, out], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, inp, ker, out\n",
        "\n",
        "dev = tvm.cuda()\n",
        "t, res, func = benchmark_conv2d_tvm(\n",
        "    make_dwsp_conv2d_gpu_scheduler_v2, B, C, H, W, K, dev, a_np, w_np, num_runs=5, repeat=5\n",
        ")\n",
        "np.testing.assert_allclose(res, ref, rtol=1e-4)\n",
        "print(f\"[TVM v2] time: {t*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5qJUlRfaCiu",
        "outputId": "a8d8c409-8a91-4406-a162-bd7dc788c45f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), depthwise_conv: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 12)\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 16)\n",
            "        for w in range(32):\n",
            "            depthwise_conv_1 = T.Buffer((6144,), data=depthwise_conv.data)\n",
            "            depthwise_conv_1[blockIdx_x * 512 + blockIdx_y * 32 + w] = T.float32(0)\n",
            "            for ry, rx in T.grid(7, 7):\n",
            "                cse_var_1: T.int32 = w + rx\n",
            "                A_1 = T.Buffer((6144,), data=A.data)\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                depthwise_conv_1[blockIdx_x * 512 + blockIdx_y * 32 + w] = depthwise_conv_1[blockIdx_x * 512 + blockIdx_y * 32 + w] + T.if_then_else(3 <= blockIdx_y + ry and blockIdx_y + ry < 19 and 3 <= cse_var_1 and cse_var_1 < 35, A_1[blockIdx_x * 512 + blockIdx_y * 32 + ry * 32 + w + rx - 99], T.float32(0)) * W_1[blockIdx_x % 4 * 49 + ry * 7 + rx]\n",
            "====================================================================================================\n",
            "[TVM v2] time: 0.0762 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt v3: v2 + 2d threads\n",
        "def make_dwsp_conv2d_gpu_scheduler_v3(B, C, H, W, K, verbose=True):\n",
        "    s, inp, ker, out, padded = base_declaration(B, C, H, W, K)\n",
        "\n",
        "    block_x = te.thread_axis(\"blockIdx.x\")\n",
        "    block_y = te.thread_axis(\"blockIdx.y\")\n",
        "    thread_x = te.thread_axis(\"threadIdx.x\")\n",
        "    thread_y = te.thread_axis(\"threadIdx.y\")\n",
        "\n",
        "    b, c, h, w = s[out].op.axis\n",
        "    bc = s[out].fuse(b, c)\n",
        "    h_outer, h_inner = s[out].split(h, factor=16)\n",
        "    w_outer, w_inner = s[out].split(w, factor=16)\n",
        "\n",
        "    s[out].bind(bc, block_x)\n",
        "    s[out].bind(h_outer, block_y)\n",
        "    s[out].bind(h_inner, thread_y)\n",
        "    s[out].bind(w_inner, thread_x)\n",
        "\n",
        "    s[padded].compute_inline()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [inp, ker, out], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, inp, ker, out\n",
        "\n",
        "dev = tvm.cuda()\n",
        "naive_time, naive_res, naive_func = benchmark_conv2d_tvm(\n",
        "    make_dwsp_conv2d_gpu_scheduler_v3, B, C, H, W, K, dev, a_np, w_np, num_runs=20, repeat=20\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM v3] time: {naive_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JPV1IAQbjwu",
        "outputId": "1519c564-667d-4e2d-e3d2-28b687dc2175"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), depthwise_conv: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 12)\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 1)\n",
            "        threadIdx_y = T.launch_thread(\"threadIdx.y\", 16)\n",
            "        for w_outer in range(2):\n",
            "            threadIdx_x = T.launch_thread(\"threadIdx.x\", 16)\n",
            "            depthwise_conv_1 = T.Buffer((6144,), data=depthwise_conv.data)\n",
            "            depthwise_conv_1[blockIdx_x * 512 + threadIdx_y * 32 + w_outer * 16 + threadIdx_x] = T.float32(0)\n",
            "            for ry, rx in T.grid(7, 7):\n",
            "                cse_var_1: T.int32 = w_outer * 16\n",
            "                A_1 = T.Buffer((6144,), data=A.data)\n",
            "                W_1 = T.Buffer((196,), data=W.data)\n",
            "                depthwise_conv_1[blockIdx_x * 512 + threadIdx_y * 32 + cse_var_1 + threadIdx_x] = depthwise_conv_1[blockIdx_x * 512 + threadIdx_y * 32 + cse_var_1 + threadIdx_x] + T.if_then_else(3 <= threadIdx_y + ry and threadIdx_y + ry < 19 and 3 <= cse_var_1 + threadIdx_x + rx and cse_var_1 + threadIdx_x + rx < 35, A_1[blockIdx_x * 512 + threadIdx_y * 32 + ry * 32 + cse_var_1 + threadIdx_x + rx - 99], T.float32(0)) * W_1[blockIdx_x % 4 * 49 + ry * 7 + rx]\n",
            "====================================================================================================\n",
            "[TVM v3] time: 0.0101 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# opt v4: v3 + fuse at hw outer\n",
        "def make_dwsp_conv2d_gpu_scheduler_v4(B, C, H, W, K, verbose=True):\n",
        "    s, inp, ker, out, padded = base_declaration(B, C, H, W, K)\n",
        "    b, c, h, w = s[out].op.axis\n",
        "    bc = s[out].fuse(b, c)\n",
        "\n",
        "    h_outer, h_inner = s[out].split(h, factor=16)\n",
        "    w_outer, w_inner = s[out].split(w, factor=16)\n",
        "    # we must reorder to do the fuse\n",
        "    s[out].reorder(bc, h_outer, w_outer, h_inner, w_inner)\n",
        "    hw_outer = s[out].fuse(h_outer, w_outer)\n",
        "\n",
        "    block_x = te.thread_axis(\"blockIdx.x\")\n",
        "    block_y = te.thread_axis(\"blockIdx.y\")\n",
        "    thread_x = te.thread_axis(\"threadIdx.x\")\n",
        "    thread_y = te.thread_axis(\"threadIdx.y\")\n",
        "\n",
        "    s[out].bind(bc, block_x)\n",
        "    s[out].bind(hw_outer, block_y)\n",
        "    s[out].bind(h_inner, thread_y)\n",
        "    s[out].bind(w_inner, thread_x)\n",
        "\n",
        "    s[padded].compute_inline()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [inp, ker, out], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "\n",
        "    return s, inp, ker, out\n",
        "\n",
        "dev = tvm.cuda()\n",
        "v4_time, v4_res, v4_func = benchmark_conv2d_tvm(\n",
        "    make_dwsp_conv2d_gpu_scheduler_v4, B, C, H, W, K, dev, a_np, w_np, num_runs=20, repeat=20\n",
        ")\n",
        "np.testing.assert_allclose(v4_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM v4] time: {v4_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii0NexyHjO7e",
        "outputId": "2d45f0e9-01db-4305-ddef-8b7d7a95ca6d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((3, 4, 16, 32), \"float32\"), W: T.Buffer((4, 1, 7, 7), \"float32\"), depthwise_conv: T.Buffer((3, 4, 16, 32), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        blockIdx_x = T.launch_thread(\"blockIdx.x\", 12)\n",
            "        blockIdx_y = T.launch_thread(\"blockIdx.y\", 2)\n",
            "        threadIdx_y = T.launch_thread(\"threadIdx.y\", 16)\n",
            "        threadIdx_x = T.launch_thread(\"threadIdx.x\", 16)\n",
            "        depthwise_conv_1 = T.Buffer((6144,), data=depthwise_conv.data)\n",
            "        depthwise_conv_1[blockIdx_x * 512 + threadIdx_y * 32 + blockIdx_y * 16 + threadIdx_x] = T.float32(0)\n",
            "        for ry, rx in T.grid(7, 7):\n",
            "            A_1 = T.Buffer((6144,), data=A.data)\n",
            "            W_1 = T.Buffer((196,), data=W.data)\n",
            "            depthwise_conv_1[blockIdx_x * 512 + threadIdx_y * 32 + blockIdx_y * 16 + threadIdx_x] = depthwise_conv_1[blockIdx_x * 512 + threadIdx_y * 32 + blockIdx_y * 16 + threadIdx_x] + T.if_then_else(3 <= threadIdx_y + ry and threadIdx_y + ry < 19 and 3 <= blockIdx_y * 16 + threadIdx_x + rx and blockIdx_y * 16 + threadIdx_x + rx < 35, A_1[blockIdx_x * 512 + threadIdx_y * 32 + ry * 32 + blockIdx_y * 16 + threadIdx_x + rx - 99], T.float32(0)) * W_1[blockIdx_x % 4 * 49 + ry * 7 + rx]\n",
            "====================================================================================================\n",
            "[TVM v4] time: 0.0080 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import te, autotvm\n",
        "\n",
        "@autotvm.template(\"depthwise_conv2d_template\")\n",
        "def depthwise_conv2d_template(B, C, H, W, K):\n",
        "    s, inp, ker, out, padded = base_declaration(B, C, H, W, K)\n",
        "    cfg = autotvm.get_config()\n",
        "\n",
        "    b, c, h, w = s[out].op.axis\n",
        "    bc = s[out].fuse(b, c)\n",
        "\n",
        "    # possible tile size\n",
        "    cfg.define_split(\"tile_h\", h, num_outputs=2)\n",
        "    cfg.define_split(\"tile_w\", w, num_outputs=2)\n",
        "\n",
        "    h_outer, h_inner = cfg[\"tile_h\"].apply(s, out, h)\n",
        "    w_outer, w_inner = cfg[\"tile_w\"].apply(s, out, w)\n",
        "\n",
        "    # reorder possibilities\n",
        "    cfg.define_knob(\"reorder_strategy\", [1, 2, 3])\n",
        "    reorder_strategy = cfg[\"reorder_strategy\"].val\n",
        "\n",
        "    if reorder_strategy == 1:\n",
        "        s[out].reorder(bc, h_outer, w_outer, h_inner, w_inner)\n",
        "    elif reorder_strategy == 2:\n",
        "        s[out].reorder(bc, h_outer, h_inner, w_outer, w_inner)\n",
        "    else:\n",
        "        s[out].reorder(bc, h_outer, w_outer, w_inner, h_inner)\n",
        "\n",
        "    hw_outer = s[out].fuse(h_outer, w_outer)\n",
        "\n",
        "    # reduce optimization\n",
        "    cfg.define_knob(\"optimize_reduce_axis\", [0, 1])\n",
        "    if cfg[\"optimize_reduce_axis\"].val:\n",
        "        ry, rx = out.op.reduce_axis\n",
        "        ryo, ryi = s[out].split(ry, factor=1)\n",
        "        rxo, rxi = s[out].split(rx, factor=1)\n",
        "        s[out].reorder(bc, hw_outer, ryo, rxo, h_inner, w_inner, ryi, rxi)\n",
        "        s[out].unroll(ryi)\n",
        "        s[out].unroll(rxi)\n",
        "\n",
        "    # use local cache\n",
        "    cfg.define_knob(\"use_local_cache\", [0, 1])\n",
        "    if cfg[\"use_local_cache\"].val:\n",
        "        local_out = s.cache_write(out, \"local\")\n",
        "        s[local_out].compute_at(s[out], hw_outer)\n",
        "\n",
        "    # use shared memory\n",
        "    cfg.define_knob(\"use_shared_memory\", [0, 1])\n",
        "    if cfg[\"use_shared_memory\"].val:\n",
        "        padded_shared = s.cache_read(padded, \"shared\", [out])\n",
        "        kernel_shared = s.cache_read(ker, \"shared\", [out])\n",
        "        s[padded_shared].compute_at(s[out], hw_outer)\n",
        "        s[kernel_shared].compute_at(s[out], hw_outer)\n",
        "\n",
        "    block_x = te.thread_axis(\"blockIdx.x\")\n",
        "    block_y = te.thread_axis(\"blockIdx.y\")\n",
        "    thread_x = te.thread_axis(\"threadIdx.x\")\n",
        "    thread_y = te.thread_axis(\"threadIdx.y\")\n",
        "\n",
        "    s[out].bind(bc, block_x)\n",
        "    s[out].bind(hw_outer, block_y)\n",
        "    s[out].bind(h_inner, thread_y)\n",
        "    s[out].bind(w_inner, thread_x)\n",
        "\n",
        "    s[padded].compute_inline()\n",
        "\n",
        "    # compiler unroll level\n",
        "    cfg.define_knob(\"unroll_level\", [0, 512, 1024, 1500])\n",
        "    if cfg[\"unroll_level\"].val > 0:\n",
        "        s[out].pragma(hw_outer, \"auto_unroll_max_step\", cfg[\"unroll_level\"].val)\n",
        "        s[out].pragma(hw_outer, \"unroll_explicit\", True)\n",
        "\n",
        "    return s, [inp, ker, out]\n",
        "\n",
        "def tune_depthwise_conv2d(B, C, H, W, K, tuning_rounds=200):\n",
        "    task = autotvm.task.create(\"depthwise_conv2d_template\",\n",
        "                               args=(B, C, H, W, K),\n",
        "                               target=\"cuda\")\n",
        "\n",
        "    print(task.config_space)\n",
        "\n",
        "    measure_option = autotvm.measure_option(\n",
        "        builder=autotvm.LocalBuilder(),\n",
        "        runner=autotvm.LocalRunner(number=10, repeat=3, min_repeat_ms=100, timeout=4)\n",
        "    )\n",
        "    log_file = \"depthwise_conv2d_autotvm.log\"\n",
        "\n",
        "    tuner = autotvm.tuner.XGBTuner(task)\n",
        "    tuner.tune(\n",
        "        n_trial=tuning_rounds,\n",
        "        measure_option=measure_option,\n",
        "        callbacks=[autotvm.callback.log_to_file(log_file)]\n",
        "    )\n",
        "\n",
        "    with autotvm.apply_history_best(log_file):\n",
        "        with tvm.target.Target(\"cuda\"):\n",
        "            s, args = depthwise_conv2d_template(B, C, H, W, K)\n",
        "            func = tvm.build(s, args)\n",
        "\n",
        "    dev = tvm.cuda(0)\n",
        "    a_np = np.random.rand(B, C, H, W).astype(\"float32\")\n",
        "    w_np = np.random.rand(C, 1, K, K).astype(\"float32\")\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((B, C, H, W), dtype=\"float32\"), dev)\n",
        "    func(a, w, b)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, dev, number=20, repeat=20)\n",
        "    time_ms = evaluator(a, w, b).mean * 1e3\n",
        "    print(f\"[AutoTVM optimized] time: {time_ms:.4f} ms\")\n",
        "\n",
        "    return func, time_ms\n",
        "\n",
        "def run_autotvm_optimization(B, C, H, W, K, tuning_rounds=50):\n",
        "    print(f\"AutoTVM: B={B}, C={C}, H={H}, W={W}, K={K}\")\n",
        "    best_func, time_ms = tune_depthwise_conv2d(B, C, H, W, K, tuning_rounds)\n",
        "    return best_func, time_ms"
      ],
      "metadata": {
        "id": "aCocFvNPnIe1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_func, time_ms = run_autotvm_optimization(B, C, H, W, K, 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz3xFkIeyjab",
        "outputId": "2c7186c7-d942-4c64-870c-3640b72b3e66"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoTVM: B=3, C=4, H=16, W=32, K=7\n",
            "ConfigSpace (len=2880, range_length=2880, space_map=\n",
            "   0 tile_h: Split(policy=factors, product=16, num_outputs=2) len=5\n",
            "   1 tile_w: Split(policy=factors, product=32, num_outputs=2) len=6\n",
            "   2 reorder_strategy: OtherOption([1, 2, 3]) len=3\n",
            "   3 optimize_reduce_axis: OtherOption([0, 1]) len=2\n",
            "   4 use_local_cache: OtherOption([0, 1]) len=2\n",
            "   5 use_shared_memory: OtherOption([0, 1]) len=2\n",
            "   6 unroll_level: OtherOption([0, 512, 1024, 1500]) len=4\n",
            ")\n",
            "[AutoTVM optimized] time: 0.0035 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mtM-xfNHVSoz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7c3d84-a4ac-40ce-a529-f78696cd5d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.11/dist-packages (0.14.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipytest) (24.2)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.11/dist-packages (from ipytest) (8.3.5)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=5.4->ipytest) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=5.4->ipytest) (1.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# pytest\n",
        "%pip install ipytest\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1Zqbo2VEVSo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9be8ee-6106-4599-e096-8c5ad8b5aea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[33m\u001b[33mno tests ran\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%%ipytest\n",
        "import tvm\n",
        "import torch\n",
        "import pytest\n",
        "import timeit\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "make_dwsp_conv2d_gpu_scheduler = make_dwsp_conv2d_gpu_scheduler_v4\n",
        "dev = tvm.cuda(0)\n",
        "\n",
        "\n",
        "def make_func(*args):\n",
        "    s, A, W, O = make_dwsp_conv2d_gpu_scheduler(*args)\n",
        "    func = tvm.build(s, [A, W, O], \"cuda\")\n",
        "    return func\n",
        "\n",
        "\n",
        "def ans_torch(a_torch, w_torch):\n",
        "    B, C, H, W = a_torch.size()\n",
        "    O, D, K1, K2 = w_torch.size()\n",
        "    assert K1 == K2\n",
        "    assert D == 1\n",
        "    K = K1\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    b_torch = F.conv2d(\n",
        "        a_torch, w_torch, bias=None, stride=1,\n",
        "        padding=((K - 1)//2), dilation=1, groups=C)\n",
        "    torch.cuda.synchronize()\n",
        "    return b_torch\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('B', [1, 2, 3, 4, 5, 11, 32])\n",
        "@pytest.mark.parametrize('C', [1, 3, 4, 64])\n",
        "@pytest.mark.parametrize('H', [1, 3, 4, 128])\n",
        "@pytest.mark.parametrize('W', [1, 3, 4, 128])\n",
        "@pytest.mark.parametrize('K', [1, 3, 5])\n",
        "def test1_M1_N1(B, C, H, W, K):\n",
        "    # Define dimension\n",
        "    func = make_func(B, C, H, W, K)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=100)\n",
        "    a_np = np.random.rand(B, C, H, W).astype(np.float32)\n",
        "    w_np = np.random.rand(C, 1, K, K).astype(np.float32)\n",
        "\n",
        "    # Torch input\n",
        "    a_torch = torch.tensor(a_np).float()\n",
        "    w_torch = torch.tensor(w_np).float()\n",
        "    b_np = ans_torch(a_torch, w_torch).detach().numpy()\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros(tuple(b_np.shape), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)\n",
        "\n",
        "@pytest.mark.parametrize(\n",
        "    'execution_number', [2, 4, 8, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
        "def test1_speed_torch(execution_number):\n",
        "    # Define dimension\n",
        "    B, C, H, W, K = 1, 5, 128, 128, 3\n",
        "    n_repeat = 100\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=1024)\n",
        "    a_np = np.random.rand(B, C, H, W).astype(np.float32)\n",
        "    w_np = np.random.rand(C, 1, K, K).astype(np.float32)\n",
        "\n",
        "    # Torch input\n",
        "    a_torch = torch.tensor(a_np).float()\n",
        "    w_torch = torch.tensor(w_np).float()\n",
        "\n",
        "    # Time the torch implementation\n",
        "    def torch_time():\n",
        "        ans_torch(a_torch, w_torch)\n",
        "    time_torch = timeit.timeit(torch_time, number=n_repeat)\n",
        "    b_torch = ans_torch(a_torch, w_torch)\n",
        "\n",
        "    # Time the optimized implementation\n",
        "    func = make_func(B, C, H, W, K)\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros(tuple(b_torch.shape), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    def tvm_time():\n",
        "        func(a, w, b)\n",
        "    time_tvm = timeit.timeit(tvm_time, number=n_repeat)\n",
        "\n",
        "    opt_folds = float(execution_number)\n",
        "    assert time_tvm * opt_folds <= time_torch, \\\n",
        "        \"%dx speed-up failed: TVM Time: %.5es TorchTime: %.5es\" \\\n",
        "        % (execution_number, time_tvm, time_torch, )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}