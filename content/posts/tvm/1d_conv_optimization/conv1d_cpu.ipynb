{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eGZIh3o1xch"
      },
      "source": [
        "# 1D Convolution on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iyx3vv_3umRF"
      },
      "source": [
        "## 2. Install TVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "01l1WUgRumRG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d01beb2d-fd40-49ec-ca0f-72149d25cdef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://tlcpack.ai/wheels\n",
            "Requirement already satisfied: tlcpack-nightly-cu102 in /usr/local/lib/python3.11/dist-packages (0.15.dev118+g51bdaec6e)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (25.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (1.14.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from tlcpack-nightly-cu102) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tlcpack-nightly-cu102 -f https://tlcpack.ai/wheels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"numpy<2.0.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc3dECsUvY5g",
        "outputId": "14781a03-4dba-4006-d569-c81da6c15297"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwbPgyceumRG"
      },
      "source": [
        "## 3. Implement `make_conv1d_cpu_scheduler_func` function in `src.ops`\n",
        "\n",
        "In that function, you are required to implemented 1D convolution and use TVM to optimize it.\n",
        "Let $x \\in \\mathbb{R}^m$ and $y \\in \\mathbb{R}^n$, then\n",
        "$$\n",
        "\\operatorname{conv1d}(x, y)_i = \\sum_{j=-\\infty}^{\\infty} x[j]y[i-j], \\forall i \\in \\{0, 1, \\dots, m + n - 1\\}\n",
        "$$\n",
        "\n",
        "Please use zero padding and unit stride. Please see the numpy convolution function for more detail: [link](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html).\n",
        "\n",
        "The `make_conv1d_cpu_scheduler_func` takes $m$ and $n$, which are the size of the two 1D input array.\n",
        "You should return both the TVM schedule and the TVM operator for\n",
        "1. Input $x$\n",
        "2. Input $y$\n",
        "3. Output $out$\n",
        "\n",
        "The schedule should be able to used to build a function with signature $func(x, y, out)$.\n",
        "Please see the following cells the usage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tvm\n",
        "import numpy as np\n",
        "from tvm import te, autotvm\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# naive baseline\n",
        "def make_conv1d_cpu_scheduler_naive(M, N):\n",
        "    A = te.placeholder((M,), name=\"A\")  # input tensor placeholder\n",
        "    W = te.placeholder((N,), name=\"W\")  # weight tensor placeholder\n",
        "\n",
        "    k = te.reduce_axis((0, M + N - 1), \"k\")   # k in [0, M+N-1)\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),   # output shape, n from (0, M + N - 1)\n",
        "        # if_then_else: if satisfy \"any\" condition, return 0 else A[k] * W[n - k]\n",
        "        lambda n: te.sum(tvm.tir.if_then_else(\n",
        "            tvm.tir.any(k < 0, k >= M, n - k < 0, n - k >= N),\n",
        "            tvm.tir.const(0.0, \"float32\"),\n",
        "            A[k] * W[n - k]), axis=k),\n",
        "        name=\"B\",\n",
        "    )\n",
        "    s = te.create_schedule(B.op)\n",
        "    print(\"=\" * 100)\n",
        "    print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    return s, A, W, B\n",
        "\n",
        "# optimize v0: shrink the range of k to reduce if else\n",
        "def make_conv1d_cpu_scheduler_v0(M, N, verbose=True):\n",
        "    A = te.placeholder((M,), name=\"A\", dtype=\"float32\")\n",
        "    W = te.placeholder((N,), name=\"W\", dtype=\"float32\")\n",
        "\n",
        "    k = te.reduce_axis((0, M), \"k\")   # k in [0, M)\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),\n",
        "        lambda n: te.sum(tvm.tir.if_then_else(\n",
        "            tvm.tir.any(k < 0, k >= M, n - k < 0, n - k >= N),\n",
        "            tvm.tir.const(0.0, \"float32\"),\n",
        "            A[k] * W[n - k]), axis=k),\n",
        "        name=\"B\",\n",
        "    )\n",
        "\n",
        "    s = te.create_schedule(B.op)\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "    return s, A, W, B\n",
        "\n",
        "# optimize v1: v0 + parallel\n",
        "def make_conv1d_cpu_scheduler_v1(M, N, verbose=True):\n",
        "    s, A, W, B = make_conv1d_cpu_scheduler_v0(M, N, False)\n",
        "    n_axis = B.op.axis[0]   # output axis\n",
        "    s[B].parallel(n_axis)   # parallel for output axis\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "    return s, A, W, B\n",
        "\n",
        "# optimize v2: v0 + parallel + split + vectorize\n",
        "def make_conv1d_cpu_scheduler_v2(M, N, factor=8, verbose=True):\n",
        "    s, A, W, B = make_conv1d_cpu_scheduler_v0(M, N, False)\n",
        "    n_axis = B.op.axis[0]\n",
        "    # AVX2, bw=256 for vectorization. 8 * float32 or 16 * float16\n",
        "    outer, inner = s[B].split(n_axis, factor=factor)\n",
        "    s[B].parallel(outer)\n",
        "    s[B].vectorize(inner)   # CPU SIMD usage\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "    return s, A, W, B\n",
        "\n",
        "# optimize v3: v2 + k_axis split + unroll\n",
        "def make_conv1d_cpu_scheduler_v3(M, N, factor=8, verbose=True):\n",
        "    s, A, W, B = make_conv1d_cpu_scheduler_v2(M, N, factor, False)\n",
        "\n",
        "    k_axis = B.op.reduce_axis[0]\n",
        "    k_outer, k_inner = s[B].split(k_axis, factor=factor)\n",
        "    s[B].unroll(k_inner)  # unroll to reduce loop overhead\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "    return s, A, W, B\n",
        "\n",
        "# optimize v4: compute refactor(minimize if-else) + parallel + split + vectorize\n",
        "def make_conv1d_cpu_scheduler_v4(M, N, factor=8, verbose=True):\n",
        "    A = te.placeholder((M,), name=\"A\", dtype=\"float32\")\n",
        "    W = te.placeholder((N,), name=\"W\", dtype=\"float32\")\n",
        "    k = te.reduce_axis((0, N), name=\"k\")\n",
        "\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),\n",
        "        lambda n: te.sum(\n",
        "            tvm.tir.if_then_else(\n",
        "                tvm.tir.all(n - k >= 0, n - k < M),\n",
        "                A[n - k] * W[k],\n",
        "                tvm.tir.const(0.0, \"float32\")\n",
        "            ),\n",
        "            axis=k\n",
        "        ),\n",
        "        name=\"B\"\n",
        "    )\n",
        "    s = te.create_schedule(B.op)\n",
        "    n_axis = B.op.axis[0]\n",
        "    outer, inner = s[B].split(n_axis, factor=factor)\n",
        "    s[B].parallel(outer)\n",
        "    s[B].vectorize(inner)   # CPU SIMD usage\n",
        "    if verbose:\n",
        "        print(\"=\" * 100)\n",
        "        print(tvm.lower(s, [A, W, B], simple_mode=True))\n",
        "        print(\"=\" * 100)\n",
        "    return s, A, W, B\n",
        "\n",
        "\n",
        "# benchmark for tvm implementation\n",
        "def benchmark_conv1d_tvm(schedule_func, M, N, device, a_np, w_np, num_runs=30, repeat=20):\n",
        "    s, A, W, B = schedule_func(M, N)\n",
        "    func = tvm.build(s, [A, W, B], target=\"llvm\")\n",
        "\n",
        "    a_tvm = tvm.nd.array(a_np, device)\n",
        "    w_tvm = tvm.nd.array(w_np, device)\n",
        "    out_tvm = tvm.nd.array(np.zeros((M + N - 1,), dtype=a_np.dtype), device)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, device, number=num_runs, repeat=repeat)\n",
        "    cost = evaluator(a_tvm, w_tvm, out_tvm).mean  # average time in seconds\n",
        "    return cost, out_tvm.asnumpy(), func, (s, A, W, B)\n",
        "\n",
        "# benchmark for numpy\n",
        "def benchmark_conv1d_numpy(a_np, w_np, num_runs=10):\n",
        "    t0 = time.time()\n",
        "    out = None\n",
        "    for _ in range(num_runs):\n",
        "        out = np.convolve(a_np, w_np)\n",
        "    t1 = time.time()\n",
        "    return (t1 - t0) / num_runs, out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZmZX8ey5vqtV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = 4096\n",
        "N = 128\n",
        "dtype = \"float32\"\n",
        "np.random.seed(0)\n",
        "a_np = np.random.rand(M).astype(dtype)\n",
        "w_np = np.random.rand(N).astype(dtype)\n",
        "ref = np.convolve(a_np, w_np)\n",
        "\n",
        "# naive TVM\n",
        "dev = tvm.cpu()\n",
        "naive_time, naive_res, naive_func, naive_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_cpu_scheduler_naive, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(naive_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Naive] time: {naive_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIq-K6fqv8JF",
        "outputId": "5fad923b-0b1d-4939-81ae-e16d6ef9ce89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for n in range(4223):\n",
            "            B[n] = T.float32(0)\n",
            "            for k in range(4223):\n",
            "                cse_var_1: T.int32 = n - k\n",
            "                B[n] = B[n] + T.if_then_else(4096 <= k or cse_var_1 < 0 or 128 <= cse_var_1, T.float32(0), A[k] * W[cse_var_1])\n",
            "====================================================================================================\n",
            "[TVM Naive] time: 24.3525 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized TVM v0\n",
        "opt_time, opt_res, opt_func, opt_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_cpu_scheduler_v0, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(opt_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Manual Opt v0] time: {opt_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxl8xPI2x-I-",
        "outputId": "57d87823-bd28-4022-95dc-3b1eb018456c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for n in range(4223):\n",
            "            B[n] = T.float32(0)\n",
            "            for k in range(4096):\n",
            "                cse_var_1: T.int32 = n - k\n",
            "                B[n] = B[n] + T.if_then_else(cse_var_1 < 0 or 128 <= cse_var_1, T.float32(0), A[k] * W[cse_var_1])\n",
            "====================================================================================================\n",
            "[TVM Manual Opt v0] time: 23.0471 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized TVM v1\n",
        "opt_time, opt_res, opt_func, opt_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_cpu_scheduler_v1, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(opt_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Manual Opt v1] time: {opt_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbO6RfMcyBj8",
        "outputId": "60839395-4686-4a09-cef3-1f4b29e7eb48"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for n in T.parallel(4223):\n",
            "            B[n] = T.float32(0)\n",
            "            for k in range(4096):\n",
            "                cse_var_1: T.int32 = n - k\n",
            "                B[n] = B[n] + T.if_then_else(cse_var_1 < 0 or 128 <= cse_var_1, T.float32(0), A[k] * W[cse_var_1])\n",
            "====================================================================================================\n",
            "[TVM Manual Opt v1] time: 22.9158 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized TVM v2\n",
        "opt_time, opt_res, opt_func, opt_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_cpu_scheduler_v2, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(opt_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Manual Opt v2] time: {opt_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2TBqQE4yCxg",
        "outputId": "9b0d83f0-e77b-4631-e2a9-f2b8aeeac4a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for n_outer in T.parallel(528):\n",
            "            for n_inner_s in range(8):\n",
            "                if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                    B[n_outer * 8 + n_inner_s] = T.float32(0)\n",
            "            for k, n_inner_s in T.grid(4096, 8):\n",
            "                if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                    cse_var_2: T.int32 = n_outer * 8 + n_inner_s\n",
            "                    cse_var_1: T.int32 = cse_var_2 - k\n",
            "                    B[cse_var_2] = B[cse_var_2] + T.if_then_else(cse_var_1 < 0 or 128 <= cse_var_1, T.float32(0), A[k] * W[cse_var_1])\n",
            "====================================================================================================\n",
            "[TVM Manual Opt v2] time: 16.0384 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized TVM v3\n",
        "opt_time, opt_res, opt_func, opt_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_cpu_scheduler_v3, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(opt_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Manual Opt v3] time: {opt_time*1e3:.4f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVWiOoD3yD3l",
        "outputId": "8a44dd00-0c70-43be-ef04-3fc43dc1491f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for n_outer in T.parallel(528):\n",
            "            for n_inner_s in range(8):\n",
            "                if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                    B[n_outer * 8 + n_inner_s] = T.float32(0)\n",
            "            for k_outer in range(512):\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_3: T.int32 = k_outer * 8\n",
            "                        cse_var_2: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_1: T.int32 = cse_var_2 - cse_var_3\n",
            "                        B[cse_var_2] = B[cse_var_2] + T.if_then_else(n_outer - k_outer < 0 or 128 <= cse_var_1, T.float32(0), A[cse_var_3] * W[cse_var_1])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_6: T.int32 = k_outer * 8\n",
            "                        cse_var_5: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_4: T.int32 = cse_var_5 - cse_var_6\n",
            "                        B[cse_var_5] = B[cse_var_5] + T.if_then_else(n_outer - k_outer < 0 or 129 <= cse_var_4, T.float32(0), A[cse_var_6 + 1] * W[cse_var_4 - 1])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_9: T.int32 = k_outer * 8\n",
            "                        cse_var_8: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_7: T.int32 = cse_var_8 - cse_var_9\n",
            "                        B[cse_var_8] = B[cse_var_8] + T.if_then_else(n_outer - k_outer < 0 or 130 <= cse_var_7, T.float32(0), A[cse_var_9 + 2] * W[cse_var_7 - 2])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_12: T.int32 = k_outer * 8\n",
            "                        cse_var_11: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_10: T.int32 = cse_var_11 - cse_var_12\n",
            "                        B[cse_var_11] = B[cse_var_11] + T.if_then_else(n_outer - k_outer < 0 or 131 <= cse_var_10, T.float32(0), A[cse_var_12 + 3] * W[cse_var_10 - 3])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_15: T.int32 = k_outer * 8\n",
            "                        cse_var_14: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_13: T.int32 = cse_var_14 - cse_var_15\n",
            "                        B[cse_var_14] = B[cse_var_14] + T.if_then_else(n_outer - k_outer < 0 or 132 <= cse_var_13, T.float32(0), A[cse_var_15 + 4] * W[cse_var_13 - 4])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_18: T.int32 = k_outer * 8\n",
            "                        cse_var_17: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_16: T.int32 = cse_var_17 - cse_var_18\n",
            "                        B[cse_var_17] = B[cse_var_17] + T.if_then_else(n_outer - k_outer < 0 or 133 <= cse_var_16, T.float32(0), A[cse_var_18 + 5] * W[cse_var_16 - 5])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_21: T.int32 = k_outer * 8\n",
            "                        cse_var_20: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_19: T.int32 = cse_var_20 - cse_var_21\n",
            "                        B[cse_var_20] = B[cse_var_20] + T.if_then_else(n_outer - k_outer < 0 or 134 <= cse_var_19, T.float32(0), A[cse_var_21 + 6] * W[cse_var_19 - 6])\n",
            "                for n_inner_s in range(8):\n",
            "                    if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                        cse_var_24: T.int32 = k_outer * 8\n",
            "                        cse_var_23: T.int32 = n_outer * 8 + n_inner_s\n",
            "                        cse_var_22: T.int32 = cse_var_23 - cse_var_24\n",
            "                        B[cse_var_23] = B[cse_var_23] + T.if_then_else(n_outer - k_outer < 0 or 135 <= cse_var_22, T.float32(0), A[cse_var_24 + 7] * W[cse_var_22 - 7])\n",
            "====================================================================================================\n",
            "[TVM Manual Opt v3] time: 14.5967 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimized TVM v4\n",
        "opt_time, opt_res, opt_func, opt_comp = benchmark_conv1d_tvm(\n",
        "    make_conv1d_cpu_scheduler_v4, M, N, dev, a_np, w_np\n",
        ")\n",
        "np.testing.assert_allclose(opt_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM Manual Opt v4] time: {opt_time*1e3:.4f} ms\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQnVBYFmyE4l",
        "outputId": "bb4c502e-75b3-4c8e-88ff-ba04a0d98858"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "# from tvm.script import ir as I\n",
            "# from tvm.script import tir as T\n",
            "\n",
            "@I.ir_module\n",
            "class Module:\n",
            "    @T.prim_func\n",
            "    def main(A: T.Buffer((4096,), \"float32\"), W: T.Buffer((128,), \"float32\"), B: T.Buffer((4223,), \"float32\")):\n",
            "        T.func_attr({\"from_legacy_te_schedule\": T.bool(True), \"tir.noalias\": T.bool(True)})\n",
            "        for n_outer in T.parallel(528):\n",
            "            for n_inner_s in range(8):\n",
            "                if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                    B[n_outer * 8 + n_inner_s] = T.float32(0)\n",
            "            for k, n_inner_s in T.grid(128, 8):\n",
            "                if T.likely(n_outer * 8 + n_inner_s < 4223):\n",
            "                    cse_var_2: T.int32 = n_outer * 8 + n_inner_s\n",
            "                    cse_var_1: T.int32 = cse_var_2 - k\n",
            "                    B[cse_var_2] = B[cse_var_2] + T.if_then_else(0 <= cse_var_1 and cse_var_1 < 4096, A[cse_var_1] * W[k], T.float32(0))\n",
            "====================================================================================================\n",
            "[TVM Manual Opt v4] time: 0.5661 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numPy baseline\n",
        "numpy_time, numpy_out = benchmark_conv1d_numpy(a_np, w_np, num_runs=10)\n",
        "print(f\"[NumPy]   time: {numpy_time*1e3:.4f} ms\")\n",
        "np.testing.assert_allclose(numpy_out, ref, rtol=1e-4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OOp117fyFlV",
        "outputId": "2d266558-2805-4a8e-a976-6e24065f8eaf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NumPy]   time: 0.2140 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDU-pOFYLXd",
        "outputId": "6a230cd2-9687-4572-e0bc-7ff5bbc3ddb8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:           6\n",
            "    Model:                85\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             3\n",
            "    BogoMIPS:             4000.22\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 cl\n",
            "                          flush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc re\n",
            "                          p_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3\n",
            "                           fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand\n",
            "                           hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp \n",
            "                          fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f a\n",
            "                          vx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveop\n",
            "                          t xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     1 MiB (1 instance)\n",
            "  L3:                     38.5 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy barriers only; no swa\n",
            "                          pgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIBRS: Not affected; BH\n",
            "                          I: Vulnerable (Syscall hardening enabled)\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tvm import autotvm\n",
        "\n",
        "@autotvm.template(\"tutorial/conv1d_auto_tune\")\n",
        "def conv1d_auto_tune(M, N):\n",
        "    A = te.placeholder((M,), name=\"A\", dtype=\"float32\")\n",
        "    W = te.placeholder((N,), name=\"W\", dtype=\"float32\")\n",
        "    k = te.reduce_axis((0, N), name=\"k\")\n",
        "\n",
        "    B = te.compute(\n",
        "        (M + N - 1,),\n",
        "        lambda i: te.sum(\n",
        "            tvm.tir.if_then_else(\n",
        "                tvm.tir.all(i - k >= 0, i - k < M),\n",
        "                A[i - k] * W[k],\n",
        "                tvm.tir.const(0.0, \"float32\")\n",
        "            ),\n",
        "            axis=k\n",
        "        ),\n",
        "        name=\"B\"\n",
        "    )\n",
        "\n",
        "    s = te.create_schedule(B.op)\n",
        "    cfg = autotvm.get_config()\n",
        "    i = B.op.axis[0]\n",
        "    k_ = B.op.reduce_axis[0]\n",
        "\n",
        "    # define search space\n",
        "    cfg.define_split(\"tile_i\", i, num_outputs=2, filter=lambda x: x.size[-1] <= 64)\n",
        "    cfg.define_split(\"tile_k\", k_, num_outputs=2, filter=lambda x: x.size[-1] <= 64)\n",
        "    cfg.define_knob(\"vectorize\", [True, False])\n",
        "    cfg.define_knob(\"unroll\", [0, 8, 16])\n",
        "\n",
        "    # schedule according to config\n",
        "    A_local = s.cache_read(A, \"local\", [B])\n",
        "    W_local = s.cache_read(W, \"local\", [B])\n",
        "\n",
        "    i_outer, i_inner = cfg[\"tile_i\"].apply(s, B, i)\n",
        "    k_outer, k_inner = cfg[\"tile_k\"].apply(s, B, k_)\n",
        "\n",
        "    s[B].parallel(i_outer)\n",
        "\n",
        "    if cfg[\"vectorize\"].val:\n",
        "        s[B].vectorize(i_inner)\n",
        "\n",
        "    unroll_factor = cfg[\"unroll\"].val\n",
        "    if unroll_factor > 0:\n",
        "        s[B].unroll(i_inner)\n",
        "\n",
        "    s[A_local].compute_at(s[B], i_outer)\n",
        "    s[W_local].compute_at(s[B], i_outer)\n",
        "\n",
        "    return s, [A, W, B]\n",
        "\n",
        "\n",
        "def tune_conv1d(M, N, trials=200, log_file=\"conv1d.log\"):\n",
        "    task = autotvm.task.create(\"tutorial/conv1d_auto_tune\", args=(M, N), target=\"llvm\")\n",
        "    print(\"AutoTVM Task:\", task.name, \"Search Space Size:\", len(task.config_space))\n",
        "\n",
        "    measure_option = autotvm.measure_option(\n",
        "        builder=autotvm.LocalBuilder(),\n",
        "        runner=autotvm.LocalRunner(number=5, repeat=1, min_repeat_ms=100)\n",
        "    )\n",
        "\n",
        "    tuner = autotvm.tuner.XGBTuner(task)\n",
        "    tuner.tune(\n",
        "        n_trial=trials,\n",
        "        measure_option=measure_option,\n",
        "        callbacks=[\n",
        "            autotvm.callback.log_to_file(log_file),\n",
        "            autotvm.callback.progress_bar(trials)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # build kernel from the best history\n",
        "    with autotvm.apply_history_best(log_file):\n",
        "        with tvm.target.Target(\"llvm\"):\n",
        "            s, arg_bufs = conv1d_auto_tune(M, N)\n",
        "            func = tvm.build(s, arg_bufs, target=\"llvm\")\n",
        "\n",
        "    return func\n",
        "\n",
        "def benchmark_conv1d_autotvm(M, N, dev, a_np, w_np, trials=200, num_runs=10):\n",
        "    func = tune_conv1d(M, N, trials=trials)\n",
        "    a_tvm = tvm.nd.array(a_np, dev)\n",
        "    w_tvm = tvm.nd.array(w_np, dev)\n",
        "    out_tvm = tvm.nd.array(np.zeros((M + N - 1,), dtype=a_np.dtype), dev)\n",
        "\n",
        "    evaluator = func.time_evaluator(func.entry_name, dev, number=num_runs, repeat=1)\n",
        "    cost = evaluator(a_tvm, w_tvm, out_tvm).mean\n",
        "    return cost, out_tvm.asnumpy()\n",
        "\n",
        "\n",
        "auto_time, auto_res = benchmark_conv1d_autotvm(\n",
        "    M, N, dev, a_np, w_np, trials=50, num_runs=10\n",
        ")\n",
        "np.testing.assert_allclose(auto_res, ref, rtol=1e-4)\n",
        "print(f\"[TVM AutoTVM] time: {auto_time*1e3:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgzvaq9PR1vO",
        "outputId": "f5a2760d-17d7-453a-8493-c7b37e210fc8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoTVM Task: tutorial/conv1d_auto_tune Search Space Size: 84\n",
            " Current/Best:    5.45/   5.89 GFLOPS | Progress: (50/50) | 89.83 s Done.\n",
            "[TVM AutoTVM] time: 0.7022 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3ozhQY7gumRH",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f55985e-ce30-4fc2-ef45-2ad0f44beb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipytest\n",
            "  Downloading ipytest-0.14.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipytest) (7.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipytest) (24.2)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.11/dist-packages (from ipytest) (8.3.5)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=5.4->ipytest) (1.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->ipytest)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipytest) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipytest) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipytest) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipytest) (0.2.13)\n",
            "Downloading ipytest-0.14.2-py3-none-any.whl (18 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipytest\n",
            "Successfully installed ipytest-0.14.2 jedi-0.19.2\n"
          ]
        }
      ],
      "source": [
        "# pytest\n",
        "%pip install ipytest\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%ipytest\n",
        "\n",
        "import tvm\n",
        "import torch\n",
        "import pytest\n",
        "import timeit\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "dev = tvm.device('llvm', 0)\n",
        "\n",
        "\n",
        "def make_conv1d_cpu_func(M, N):\n",
        "    s, A, W, O = make_conv1d_cpu_scheduler_v4(M, N)\n",
        "    func = tvm.build(s, [A, W, O], \"llvm\")\n",
        "    return func\n",
        "\n",
        "\n",
        "def ans_np(a_np, w_np):\n",
        "    a_np = a_np.flatten()\n",
        "    w_np = w_np.flatten()\n",
        "    return np.convolve(a_np, w_np)\n",
        "\n",
        "\n",
        "def ans_torch(a_torch, w_torch):\n",
        "    M, N = a_torch.size(0), w_torch.size(0)\n",
        "    b_torch = F.conv1d(a_torch, w_torch, bias=None, stride=1,\n",
        "                       padding=(N - 1), dilation=1, groups=1)\n",
        "    return b_torch\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('execution_number', range(5))\n",
        "def test1_M1_N1(execution_number):\n",
        "    # Define dimension\n",
        "    M = 1\n",
        "    N = 1\n",
        "    func = make_conv1d_cpu_func(M, N)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=execution_number)\n",
        "    a_np = np.random.rand(M).astype(np.float32)\n",
        "    w_np = np.random.rand(N).astype(np.float32)\n",
        "    b_np = ans_np(a_np, w_np)\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('execution_number', [1, 10, 100, 1000, 10000])\n",
        "def test1_Mvar_N1024(execution_number):\n",
        "    # Define dimension\n",
        "    M = execution_number\n",
        "    N = 1024\n",
        "    func = make_conv1d_cpu_func(M, N)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=1024)\n",
        "    a_np = np.random.rand(M).astype(np.float32)\n",
        "    w_np = np.random.rand(N).astype(np.float32)\n",
        "    b_np = ans_np(a_np, w_np)\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)\n",
        "\n",
        "\n",
        "@pytest.mark.parametrize('execution_number', [1, 10, 100, 1000, 10000])\n",
        "def test1_M1024_Nvar(execution_number):\n",
        "    # Define dimension\n",
        "    M = 1024\n",
        "    N = execution_number\n",
        "    func = make_conv1d_cpu_func(M, N)\n",
        "\n",
        "    # Create random test data\n",
        "    np.random.seed(seed=1024)\n",
        "    a_np = np.random.rand(M).astype(np.float32)\n",
        "    w_np = np.random.rand(N).astype(np.float32)\n",
        "    b_np = ans_np(a_np, w_np)\n",
        "\n",
        "    a = tvm.nd.array(a_np, dev)\n",
        "    w = tvm.nd.array(w_np, dev)\n",
        "    b = tvm.nd.array(np.zeros((M + N - 1), dtype='float32'), dev)\n",
        "    func(a, w, b)\n",
        "    b_out = b.numpy()\n",
        "\n",
        "    assert b_np.shape == b_out.shape, \\\n",
        "        \"Shape mismatch: \" + str(b_np.shape) + \"\\t\" + str(b_out.shape)\n",
        "    assert np.allclose(b_np, b_out), \"Value mismatch: %s %s\" % (b_np, b_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG_tkFicwhNy",
        "outputId": "84178c17-8924-47b6-d2d7-eee6d8c686d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                              [100%]\u001b[0m\n",
            "\u001b[32m\u001b[32m\u001b[1m15 passed\u001b[0m\u001b[32m in 4.20s\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}